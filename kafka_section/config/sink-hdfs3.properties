name=hdfs-sink
connector.class=io.confluent.connect.hdfs3.Hdfs3SinkConnector
tasks.max=1
topics=postgresql-db-source-shoppingproducts,sales_feed,mysql-db-source-Customers,mysql-db-source-Locations,mysql-db-source-OrderDetails,mysql-db-source-Orders,mysql-db-source-Products
hdfs.url=hdfs://localhost:9000 

confluent.topic.bootstrap.servers=localhost:9092
confluent.topic.replication.factor=1

format.class=io.confluent.connect.hdfs3.json.JsonFormat
topics.dir=datalake
logs.dir=datalake/logs

flush.size=100
rotate.interval.ms=3600000
partitioner.class=io.confluent.connect.storage.partitioner.DailyPartitioner
locale=ar_JO
timezone=Africa/Abidjan

# format.class=io.confluent.connect.hdfs3.avro.AvroFormat
# key.converter=org.apache.kafka.connect.storage.StringConverter
# value.converter=io.confluent.connect.avro.AvroConverter
# value.converter.schema.registry.url=http://localhost:8081
# format.class=io.confluent.connect.hdfs.avro.AvroFormat
# avro.codec=null