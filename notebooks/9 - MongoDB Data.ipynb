{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fcd92e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import re\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import math\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b37726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database(db_name):\n",
    "    CONNECTION_STRING = \"mongodb://modaj:123m@localhost:27017/{}\".format(db_name)\n",
    "    client = MongoClient(CONNECTION_STRING)\n",
    "    return client[db_name] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074eceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "symb_re3 = re.compile(r\"\"\"[^a-zA-Z0-9\\s]+\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618f721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "symb_re2 = re.compile(r\"\"\"[\\W_]+\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05d6f0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial string :  59 year abc555jw:, .’’’’@! eiw\n",
      "final string 59 year abc555jw  eiw\n"
     ]
    }
   ],
   "source": [
    "ini_string = \"59 year abc555jw:, .’’’’@! eiw\"\n",
    " \n",
    "# printing initial string\n",
    "print (\"initial string : \", ini_string)\n",
    "\n",
    "result = symb_re3.sub(repl=\"\", string=ini_string)\n",
    "\n",
    "# printing final string\n",
    "print (\"final string\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "558d9a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial string :  abc555jw:, .’’’’@! eiw\n",
      "final string abc555jweiw\n"
     ]
    }
   ],
   "source": [
    "ini_string = \"abc555jw:, .’’’’@! eiw\"\n",
    " \n",
    "# printing initial string\n",
    "print (\"initial string : \", ini_string)\n",
    " \n",
    "result = re.sub('[\\W_]+', '', ini_string)\n",
    " \n",
    "# printing final string\n",
    "print (\"final string\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebec642f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (2410742179.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    remove_symbols(\"L LIKED 50 Rolls Compatible with Dymo 30336 1)\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "remove_symbols(\"L LIKED 50 Rolls Compatible with Dymo 30336 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb7d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# symb_re = re.compile(r\"\"\"[!\"#$%&\\'()*+,-./’:;<=>?@[\\\\\\]^_`{|}~،؟…«“\\\":\\\"…”]\"\"\")\n",
    "# symb_re2 = re.compile(r\"\"\"[\\W_]+\"\"\")\n",
    "symb_re3 = re.compile(r\"\"\"[^a-zA-Z0-9\\s]+\"\"\")\n",
    "def remove_symbols(text: str) -> str:\n",
    "    return symb_re3.sub(repl=\"\", string=text)\n",
    "\n",
    "def replace_non_dates(date_i):\n",
    "    if type(date_i) == str:\n",
    "        if date_i[-1] ==\"m\" or date_i[-1] ==\"s\" or date_i[-1] ==\"h\":\n",
    "            date_i = date.today()\n",
    "            return date_i\n",
    "        elif \",\" not in date_i:\n",
    "            if date_i.split()[-1].isnumeric():\n",
    "                date_i = date_i + \", {}\".format(date.today().year)\n",
    "            else:\n",
    "                date_i = date.today()\n",
    "            return date_i\n",
    "    return date_i\n",
    "\n",
    "def convert_number(num_i):\n",
    "    if type(num_i) == str:\n",
    "        num_i = num_i.replace(',', '')\n",
    "        if \"K\" in num_i:\n",
    "            if \".\" in num_i:\n",
    "                num_i = num_i.replace('.', '')[:-1]\n",
    "                num_i = int(num_i) * 100\n",
    "            else:\n",
    "                num_i = int(num_i[:-1]) * 1000\n",
    "        elif \"M\" in num_i:\n",
    "            if \".\" in num_i:\n",
    "                num_i = num_i.replace('.', '')[:-1]\n",
    "                num_i = int(num_i) * 100000\n",
    "            else:\n",
    "                num_i = int(num_i[:-1]) * 1000000\n",
    "        return num_i\n",
    "    elif num_i == None:\n",
    "        return -1\n",
    "    else:\n",
    "        return int(num_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f2246f",
   "metadata": {},
   "source": [
    "## `1) Amazon Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5b4f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "amazon_product_data = pd.read_csv(\"../Datasets/product_amazon_data_pt1.csv\")\n",
    "amazon_product_data = amazon_product_data.rename(columns={\"Unnamed: 0\": \"product_id_AMA\"})\n",
    "amazon_product_cols = amazon_product_data.columns.tolist() # columns list\n",
    "# amazon_product_data = amazon_product_data.values # Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6481d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING (should be added to the scraping process)\n",
    "amazon_product_data[\"review_text\"] = amazon_product_data[\"review_text\"].astype(\"str\")\n",
    "\n",
    "amazon_product_data[\"product\"] = list(map(lambda x: x.replace(\":\", \"\"), amazon_product_data['product']))\n",
    "amazon_product_data[\"product\"] = list(map(remove_symbols, amazon_product_data['product']))\n",
    "amazon_product_data[\"amazon_product_name\"] = list(map(lambda x: x.replace(\":\", \"\"), \n",
    "                                                          amazon_product_data['amazon_product_name']))\n",
    "amazon_product_data[\"amazon_product_name\"] = list(map(remove_symbols, \n",
    "                                                          amazon_product_data['amazon_product_name']))\n",
    "amazon_product_data[\"review_text\"] = list(map(lambda x: x.replace(\":\", \"\"), \n",
    "                                                          amazon_product_data['review_text']))\n",
    "amazon_product_data[\"review_text\"] = list(map(remove_symbols, \n",
    "                                                          amazon_product_data['review_text']))\n",
    "\n",
    "amazon_product_data[\"rating\"] = list(map(lambda x: x.split()[0], amazon_product_data['rating']))\n",
    "amazon_product_data[\"rating\"] = amazon_product_data[\"rating\"].astype(float)\n",
    "\n",
    "amazon_product_data[\"review_count\"] = list(map(lambda x: x.split()[0].replace(\",\", \"\"), amazon_product_data['review_count']))\n",
    "amazon_product_data[\"review_count\"] = amazon_product_data[\"review_count\"].astype(int)\n",
    "\n",
    "amazon_product_data[\"price\"] =  list(map(lambda x: x[1:] if type(x)==str else -1, \n",
    "                                         amazon_product_data['price']))\n",
    "amazon_product_data[\"price\"] = amazon_product_data[\"price\"].astype(float)\n",
    "\n",
    "amazon_product_data['review_date'] = list(map(replace_non_dates, amazon_product_data['review_date']))\n",
    "amazon_product_data['review_date'] = pd.to_datetime(amazon_product_data['review_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30ce4fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE / USE database - 'amazon_product_reviews_db'\n",
      "CREATE / USE collection - 'product_reviews'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create/use database\n",
    "dbname = \"amazon_product_reviews_db\"\n",
    "AMA_mongo_DB = get_database(db_name=dbname)\n",
    "print(\"CREATE / USE database - '{}'\".format(dbname))\n",
    "\n",
    "# create/use collection\n",
    "collname = \"product_reviews\"\n",
    "mongo_coll = AMA_mongo_DB[collname]\n",
    "print(\"CREATE / USE collection - '{}'\".format(collname))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bca392b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x7f8e542d4b50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # empty collection\n",
    "mongo_coll.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84fdcaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted - 1000 documents\n",
      "Inserted - 1000 documents\n",
      "Inserted - 1000 documents\n",
      "Inserted - 1000 documents\n",
      "Inserted - 682 documents\n"
     ]
    }
   ],
   "source": [
    "# insert data\n",
    "insert_batch = 1000\n",
    "batch_num = math.ceil(amazon_product_data.shape[0] / 1000)\n",
    "\n",
    "for i in range(batch_num):\n",
    "    data_insert = amazon_product_data[(i)*insert_batch: (i+1)*insert_batch]\n",
    "    mongo_coll.insert_many(data_insert.to_dict(orient=\"records\"))\n",
    "    print(\"Inserted - {} documents\".format(data_insert.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e805f6",
   "metadata": {},
   "source": [
    "## `2) Twitter Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a52711dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_product_data = pd.read_csv(\"../Datasets/product_twitter_data_pt2_2.csv\")\n",
    "twitter_product_data = twitter_product_data.rename(columns={\"Unnamed: 0\": \"tweet_id\"})\n",
    "twitter_product_cols = twitter_product_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c87148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING (should be added to the scraping process)\n",
    "twitter_product_data[\"product\"] = twitter_product_data[\"product\"].astype(\"str\")\n",
    "twitter_product_data[\"tweet_poster\"] = twitter_product_data[\"tweet_poster\"].astype(\"str\")\n",
    "twitter_product_data[\"tweet_text\"] = twitter_product_data[\"tweet_text\"].astype(\"str\")\n",
    "twitter_product_data[\"product\"] = list(map(lambda x: x.replace(\":\", \"\"), twitter_product_data['product']))\n",
    "twitter_product_data[\"tweet_poster\"] = list(map(lambda x: x.replace(\":\", \"\"), \n",
    "                                                     twitter_product_data['tweet_poster']))\n",
    "twitter_product_data[\"tweet_poster\"] = list(map(remove_symbols, \n",
    "                                                     twitter_product_data['tweet_poster']))\n",
    "twitter_product_data[\"tweet_mention\"] = list(map(lambda x: x.replace(\":\", \"\"), \n",
    "                                                     twitter_product_data['tweet_mention']))\n",
    "twitter_product_data[\"tweet_mention\"] = list(map(remove_symbols, \n",
    "                                                     twitter_product_data['tweet_mention']))\n",
    "twitter_product_data[\"tweet_text\"] = list(map(lambda x: x.replace(\":\", \"\"), \n",
    "                                                     twitter_product_data['tweet_text']))\n",
    "twitter_product_data[\"tweet_text\"] = list(map(remove_symbols, \n",
    "                                                     twitter_product_data['tweet_text']))\n",
    "\n",
    "twitter_product_data[\"num_comments\"] = list(map(convert_number, twitter_product_data['num_comments']))\n",
    "twitter_product_data[\"num_comments\"] =  twitter_product_data[\"num_comments\"].astype(int)\n",
    "\n",
    "twitter_product_data[\"num_retweets\"] = list(map(convert_number, twitter_product_data['num_retweets']))\n",
    "twitter_product_data[\"num_retweets\"] =  twitter_product_data[\"num_retweets\"].astype(int)\n",
    "\n",
    "twitter_product_data[\"num_likes\"] = list(map(convert_number, twitter_product_data['num_likes']))\n",
    "twitter_product_data[\"num_likes\"] =  twitter_product_data[\"num_likes\"].astype(int)\n",
    "\n",
    "twitter_product_data[\"num_views\"] = list(map(convert_number, twitter_product_data['num_views']))\n",
    "twitter_product_data[\"num_views\"] =  twitter_product_data[\"num_views\"].astype(int)\n",
    "\n",
    "twitter_product_data['tweet_date'] = list(map(replace_non_dates, twitter_product_data['tweet_date']))\n",
    "twitter_product_data['tweet_date'] = pd.to_datetime(twitter_product_data['tweet_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1db461e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE / USE database - 'twitter_sentiment_db'\n",
      "CREATE / USE collection - 'tweet_collection'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create/use database\n",
    "dbname = \"twitter_sentiment_db\"\n",
    "mongo_DB = get_database(db_name=dbname)\n",
    "print(\"CREATE / USE database - '{}'\".format(dbname))\n",
    "\n",
    "# create/use collection\n",
    "collname = \"tweet_collection\"\n",
    "mongo_coll = mongo_DB[collname]\n",
    "print(\"CREATE / USE collection - '{}'\".format(collname))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62ad2a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.DeleteResult at 0x7f8e52ff8820>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # empty collection\n",
    "mongo_coll.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3d24d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted - 1000 documents\n",
      "Inserted - 1000 documents\n",
      "Inserted - 1000 documents\n",
      "Inserted - 1000 documents\n",
      "Inserted - 1000 documents\n",
      "Inserted - 1000 documents\n",
      "Inserted - 1000 documents\n",
      "Inserted - 1000 documents\n",
      "Inserted - 1000 documents\n",
      "Inserted - 1000 documents\n",
      "Inserted - 109 documents\n"
     ]
    }
   ],
   "source": [
    "# insert data\n",
    "insert_batch = 1000\n",
    "batch_num = math.ceil(twitter_product_data.shape[0] / 1000)\n",
    "\n",
    "for i in range(batch_num):\n",
    "    data_insert = twitter_product_data[(i)*insert_batch: (i+1)*insert_batch]\n",
    "    mongo_coll.insert_many(data_insert.to_dict(orient=\"records\"))\n",
    "    print(\"Inserted - {} documents\".format(data_insert.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataEngineeringKer",
   "language": "python",
   "name": "dataengineeringker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
