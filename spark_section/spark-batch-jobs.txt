# Variables
SPARK_HOME=/home/modaj/Tools/spark-3.3.1-bin-hadoop3
PROJECT_DIR=/home/modaj/Workspace/Projects/DE_Sales_Data

# Scheduled Running of Scripts (daily)
0 13  * * * $SPARK_HOME/bin/spark-submit --master yarn --deploy-mode cluster --driver-memory 4g --executor-memory 2g --executor-cores 2 --queue default --class "ps_dm" --packages com.datastax.spark:spark-cassandra-connector_2.12:3.3.0 --files $SPARK_HOME/conf/hive-site.xml,$SPARK_HOME/conf/hdfs-site.xml,$SPARK_HOME/conf/core-site.xml --conf spark.sql.warehouse.dir=hdfs://localhost:9000/user/hive/warehouse $PROJECT_DIR/spark_section/spark_scripts/product_sentiments_dm/target/scala-2.12/de_sales-etl-data-mart-product-sentiments_2.12-1.0.jar
0 14  * * * $SPARK_HOME/bin/spark-submit --master yarn --deploy-mode cluster --driver-memory 4g --executor-memory 2g --executor-cores 2 --queue default --class "er_dm" --files $SPARK_HOME/conf/hive-site.xml,$SPARK_HOME/conf/hdfs-site.xml,$SPARK_HOME/conf/core-site.xml $PROJECT_DIR/spark_section/spark_scripts/ecommerce_reviews_dm/target/scala-2.12/de_sales-etl-data-mart-ecommerce-reviews_2.12-1.0.jar
0 15  * * * $SPARK_HOME/bin/spark-submit --master yarn --deploy-mode cluster --driver-memory 4g --executor-memory 2g --executor-cores 2 --queue default --class "oh_dm" --files $SPARK_HOME/conf/hive-site.xml,$SPARK_HOME/conf/hdfs-site.xml,$SPARK_HOME/conf/core-site.xml $PROJECT_DIR/spark_section/spark_scripts/order_history_dm/target/scala-2.12/de_sales-etl-data-mart-order-history_2.12-1.0.jar

0 16  * * * $SPARK_HOME/bin/spark-submit --master yarn --deploy-mode cluster --driver-memory 4g --executor-memory 2g --executor-cores 2 --queue default --class "pp_sl" --files $SPARK_HOME/conf/hive-site.xml,$SPARK_HOME/conf/hdfs-site.xml,$SPARK_HOME/conf/core-site.xml --packages com.datastax.spark:spark-cassandra-connector_2.12:3.3.0 $PROJECT_DIR/spark_section/spark_scripts/product_performance_sl/target/scala-2.12/de_sales-etl-serving-layer-product-performance_2.12-1.0.jar
0 17  * * * $SPARK_HOME/bin/spark-submit --master yarn --deploy-mode cluster --driver-memory 4g --executor-memory 2g --executor-cores 2 --class "bs_sl" --files $SPARK_HOME/conf/hive-site.xml,$SPARK_HOME/conf/hdfs-site.xml,$SPARK_HOME/conf/core-site.xml --packages com.datastax.spark:spark-cassandra-connector_2.12:3.3.0 $PROJECT_DIR/spark_section/spark_scripts/branch_sales_sl/target/scala-2.12/de_sales-etl-serving-layer-branch-sales_2.12-1.0.jar
0 18  * * * $SPARK_HOME/bin/spark-submit --master yarn --deploy-mode cluster --driver-memory 4g --executor-memory 2g --executor-cores 2 --class "cps_sl" --files $SPARK_HOME/conf/hive-site.xml,$SPARK_HOME/conf/hdfs-site.xml,$SPARK_HOME/conf/core-site.xml --packages com.datastax.spark:spark-cassandra-connector_2.12:3.3.0 $PROJECT_DIR/spark_section/spark_scripts/customer_preference_sales_sl/target/scala-2.12/de_sales-etl-serving-layer-customer-preferences-and-sales_2.12-1.0.jar
0 19  * * * $SPARK_HOME/bin/spark-submit --master yarn --deploy-mode cluster --driver-memory 4g --executor-memory 2g --executor-cores 2 --class "tos_sl" --files $SPARK_HOME/conf/hive-site.xml,$SPARK_HOME/conf/hdfs-site.xml,$SPARK_HOME/conf/core-site.xml --packages com.datastax.spark:spark-cassandra-connector_2.12:3.3.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.2 $PROJECT_DIR/spark_section/spark_scripts/timely_order_sales_sl/target/scala-2.12/de_sales-etl-serving-layer-timely-order-sales_2.12-1.0.jar 
0 20  * * * $SPARK_HOME/bin/spark-submit --master yarn --deploy-mode cluster --driver-memory 4g --executor-memory 2g --executor-cores 2 --class "future_sl" --files $SPARK_HOME/conf/hive-site.xml,$SPARK_HOME/conf/hdfs-site.xml,$SPARK_HOME/conf/core-site.xml --packages com.datastax.spark:spark-cassandra-connector_2.12:3.3.0 $PROJECT_DIR/spark_section/spark_scripts/future_sales_sl/target/scala-2.12/de_sales-etl-serving-layer-future-sales_2.12-1.0.jar 



